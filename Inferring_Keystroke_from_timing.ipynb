{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inferring_Keystroke_from_timing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glmy7MKAwIWa"
      },
      "source": [
        "\n",
        "\n",
        "*   Step1:Gaussian Modeling\n",
        "\n",
        "*   Step2:Given a sequence of latencies, figure out the states(aka     character pairs)\n",
        "*   Using n viterbi algorithm for computing the most likely character pair sequence\n",
        "*   Inferring character sequence from character pairs\n",
        "*   For the time being, generate 10 most likely sequences or n=10, decide later what best n should be after running signal images through CNN LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiqhQUWcFOWO"
      },
      "source": [
        "Gaussian Modelling part: We have a dataset of mean and standard deviation of inter keystroke timing for each character pair. This dataset is a dictionary with character pair as keys and [sigma,mu] as vallues for each character pair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm_pxus0FfGM"
      },
      "source": [
        "#dataset: character_pair->(mu,sigma) \n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "def gaussian_modeling(character_pair,time):\n",
        "    return scipy.stats.norm(dataset[character_pair][0],datatset[character_pair][1]).pdf(time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Caa3KYmLVpR"
      },
      "source": [
        "def prob(time,state):\n",
        "    '''returns the value of p(state|time)'''\n",
        "    sum = 0\n",
        "    for elt in dataset:\n",
        "        sum+=gaussian_modeling(elt,time)\n",
        "    return gaussian_modeling(state,time)/sum\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_wDEWfzKgWc"
      },
      "source": [
        "Steps of nviterbi algorithm:\n",
        "\n",
        "\n",
        "*   Initialize the class with value of n and total states\n",
        "*   When t=1, initialize all states with a value which is given the equal to P(state|time), store these values in a dictionary. Call this dictionary v. V[(q,1)]=p(q|y1) for all possible qs\n",
        "*   The above value is got by the function above\n",
        "*   Maintain a class variable of predesssor states(26) for each state[We have total 26*26 total states]\n",
        "*   Defining variable for viterbi is n which is the total number of predecessor candidates for each state  \n",
        "*   For time t>1, we have to find n best candidates for each state \n",
        "*   When t = 2, each state has total 26 ingoing arrows, we take the n best one among 26 states\n",
        "*   This equation p[q_2|y_2]=p[y_2|q_2]p[q_2|q_1]p[q_1|y_1] for all predecessor q1 of q2 and select n best q1s for each state q2\n",
        "*   Now start maintaining a dictionary with keys in the form (state,time) starting from time t=2 and like the above example (q2,2) will map to a list of (predecessor_state,value) so the n best predecessor states and the value of p[q2|y2] for each q1. Call that dictionary V. So V[(q2,2)]= [(q1,p[q2|y2]),(),(),()...]\n",
        "*   Starting from t=3, for a state q, for all its predecessor q' and t-1, we look through the values of  (q',t-1) in the dictionary and write a function that finds the best ns among these 26*n values and then update the dictionary with these values-\n",
        "V[(state,3)]=[(state1,state2,value),(state1,state2,value),(state1,state2,),()] value is \n",
        "p(q3|y3)=p(y3|q3)p(q3|q2)p(q2|y2)\n",
        "*   At the given final state, we have 26*n paths, we take the n best among them and store them for future CNNLSTM purpose.\n",
        "*   Finally, we save the n best candidates \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx9cE0qDZBfK"
      },
      "source": [
        "def find_best_n(prev_list,n,new_state):\n",
        "    if new state:\n",
        "        result_list = []\n",
        "        for i in range(len(prev_list)):\n",
        "            if i<n:\n",
        "                new_tup = (new_state,)+prev_list[i]\n",
        "                result_list.append(new_tup)\n",
        "            else:\n",
        "                curr_min = min(l,key lambda e:e[-1])\n",
        "                if curr_min<prev_list[i][-1]:\n",
        "                    ind = result_list.index(curr_min)\n",
        "                    result_list.pop(ind)\n",
        "                    new_tup = (new_state,)+prev_list[i]\n",
        "                    result_list.append(new_tup)\n",
        "    else:\n",
        "        result_list = []\n",
        "        for i in range(len(prev_list)):\n",
        "            if i<n:\n",
        "                result_list.append(prev_list[i])\n",
        "            else:\n",
        "                curr_min = min(l,key lambda e:e[-1])\n",
        "                if curr_min<prev_list[i][-1]:\n",
        "                    ind = result_list.index(curr_min)\n",
        "                    result_list.pop(ind)\n",
        "                    result_list.append(prev_list[i])\n",
        "    return result_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4764zvZQLzWQ"
      },
      "source": [
        "#dataset: character_pair->(mu,sigma) \n",
        "def n_viterbi_algorithm(n,character_set,time_sequence):\n",
        "    #Generate All states \n",
        "    states = set()\n",
        "    for character1 in character_set:\n",
        "        for character2 in character_set:\n",
        "            states.add((character1,character2))\n",
        "    predecessor_dictionary = {}\n",
        "    for state in states:\n",
        "        predecessor_dictionary[state]=[]\n",
        "        for char in character_set:\n",
        "            predecessor_dictionary[state].append((state[1],char))\n",
        "    #generate values for time =1 and initialize a dictionary  \n",
        "    V = {}\n",
        "    for state in states:\n",
        "        V[(state,1)] = [(state,prob(time_sequence[0],state))]\n",
        "    for i in range(1,len(time_sequence)):\n",
        "        for state in states:\n",
        "            scale_value = gaussian_modeling(state,time_sequence[i])*(1/len(character_set))\n",
        "            prev_list = []\n",
        "            for prev in predecessor_dictionary[state]:\n",
        "                prev_list.append(V[(prev,i)])\n",
        "            modified_list = find_best_n(prev_list,n,state)\n",
        "            for i in range(len(modified_list)):\n",
        "                elt = modified_list[i][:-1]+(modified_list[i][-1]*scale_value,)\n",
        "                modified_list[i] = elt\n",
        "            V[(state,i+1)] = modified_list\n",
        "    final_path_list = []\n",
        "    for state in states:\n",
        "        final_path_list.append(V[(state,len(time_sequence))])\n",
        "    best_n_path = find_best_n(prev_list,n,new_state)\n",
        "    return best_n_path"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}